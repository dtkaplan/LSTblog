---
title: "*Instructor's Note: Likelihood"
author: "Daniel Kaplan"
date: "2024-02-26"
categories: [likelihood, instructor note]
---

```{r include=FALSE}
library(LSTbook)
```

When I introduce the statistical concept of *likelihood* in instructor workshops covering *Lessons in Statistical Thinking*, there are two reactions that I see almost every time.

i. Isn't *likelihood* too advanced a topic for introductory statistics? It belongs in the junior-level mathematical statistics course.
ii. What is likelihood? This is particular prevalent among instructors whose main contact with statistics has been teaching an introductory course, as so often happens when mathematicians are drafted to teach intro stats.

The purpose of this post is two-fold: to explain why likelihood is an important topic for understanding statistics and to point out my approach to teaching likelihood which I think makes the concept easier to grasp than the standard exposition. If you want an introduction to likelihood first, I encourage you to look at Lessons 16, 26, 27, and 28 of *LST*.

You may know that the history of statistics is full of disputes between the so-called "frequentists" and the "Bayesians." (Such disputes occasionally crop up even today, but I think the broad trend is to see them as related, but complementary aspects of statistical inference and method.) Introductory statistics textbooks are almost always written from the frequentist point of view, and many don't even mention Bayes. On the other hand, data scientists and engineers tend not to dwell on frequentist ideas, but treat the Bayesian approach as useful for decision making.

Both frequentist and Bayesian perspectives place great emphasis on the idea of likelihood. For instance, the frequentists' p-value is a likelihood and frequentist estimates are often made using a maximum likelihood procedure. For Bayesians, likelihood functions are the means by which a prior is updated into a posterior. 

Accepting the previous paragraph as showing that likelihood is a mainstream topic broadly in statistical thinking, I to considering  whether likelihood is too difficult for introductory students.

I think many instructors will be sympathetic to the claim that Bayes Rule, in the format commonly used, is easy to derive but hard to interpret. Here's the common format that I mean, that relates conditional and marginal probabilities:

$$p(A | B) = \frac{p(B | A) p(A)}{p(B)}$$
How to find the quantity $p(B)$ is often a mystery to students. One common explanation is, "Don't worry about $p(B)$ is just a normalizing factor." How to calculate this normalizing factor? The answer, in practice, is that $$p(B) = p(B|A) p(A) + p(B| not\ A) p(not\ A)\ .$$

What does this have to do with *likelihood*? Both $p(B | A)$ and $p(B | not\ A)$ are likelihoods.

At least three things get in the way of assimilating the meaning of a likelihood from the Bayes Rule formula.

i. "Likelihood" seems like an arbitrary name assigned to certain configuration of conditional probabilities but not others. And why isn't $p(A|B)$ called a likelihood? (It's not, it's a posterior probability. But it looks very much like a likelihood.)
ii. In for formula, A and B look like they are the same thing, or perhaps different possible outcomes of the same event: either A or B. But really, A and B refer to two different kinds of things. For example, B might be whether a patient is sick or healthy while A is whether the clinical test comes up positive or negative. That is, there are multiple possibilities (e.g. sick/healthy) for the thing called A and a different set of multiple possibilities for the thing call B (e.g. + or - test result). This is implicit in the formula; there's nothing to remind the reader that A is one kind of thing and B is another.
iii. It's not too hard to introduce the concept of joint, conditional, and marginal probabilities with a two-by-two table of counts. Pointing out that a likelihood is a kind of conditional probability is a tempting pedagogical route: First nail conditional probability using tables or a graph relating areas, then explain that a likelihood is a conditional probability of the same sort as the ones that were so easy when we had a two-by-two table. It might even be a good route ... except experience shows that the road has traps and pitfalls.

Now I'm not disputing the mathematics that a likelihood is a kind of conditional probability. But "likelihood" is not a synonym for "conditional probability." Our pedagogy ought to make clear what kinds of conditional probabilities are likelihoods. 

I take a different route. A minor part of this is to bypass the normalization in Bayes rule by saying that p() is a relative probability. We can do all the calculations without normalizing, waiting until we need to present the results as (non-relative) probabilities at the time we present the results to our client.

The major feature of my different route has to do with making certain and obvious that A and B are different kinds of things. One of the kinds of things is an outcome of an event, for instance, the event of taking a clinical test, which produces + or - result where some randomness may be involved.

The other kind of thing is a **hypothesis**. The word "hypothesis" is not a stranger to traditional Stat 101 where it appears in two guises: the Null hypothesis and the Alternative hypothesis.

But I introduce hypothesis more generally, in the sense used in the scientific method and philosophy. A hypothesis is merely a statement that might or might not be true in the real world. For example, "Bill is sick" is a hypothesis, as is "Bill is healthy." A simulation (Lesson 14) is a hypothesis.

To give students a more concrete image of a hypothesis, I analogize them to planets. Imagine that you can create a planet, perhaps by simulation, in which things happen according to an exactly known process. You could also create a different planet, in which things happen by another process, which is also completely known. These planets are like hypotheses; you get to say what is going on (the statement) but it isn't necessarily even close to what's going on here on Earth (the statement might or might not be true).

So think of the B in Bayes rule as indicating which planet you are on.

The A in Bayes rule is not a hypothesis. Instead, it is an observation. For instance, "Bill had a positive test result" is a possible observation, as is "Bill had a negative test result." Since A has already been observed, there's no reason to worry about the probability of A.

Now for likelihood, in concrete terms. Imagine you are on Planet B_sick_, the planet inhabited only by sick people. If you performed the clinical test on these sick people, a given individual might have a positive or a negative test result. The probability of a positive result, given that you are on Planet B_sick_ is what we call a likelihood. You calculate that likelihood knowing absolutely that you are, for the purposes of the calculation, on Planet B_sick_. (In detection theory, the probability of a + test result from an inhabitant of Planet B_sick_ is called the *sensitivity* of the test. Sensitivity is a likelihood.)

Of course, you might decide to go to Planet B_healthy_, where all the inhabitants are healthy. On this planet, a negative test result is what's expected, but the test is imperfect so we refer to the probability of a negative test (on Planet B_healthy_). This probability is a likelihood.

A p-value is a likelihood. The planet involved is Planet Null, the planet where all model coefficients would be seen as zero, at least in the limit where an infinite amount of data is collected. You have an observation (from Planet Earth) of a model coefficient. The p-value is the likelihood of that Earthy observation (or more extreme) if you had conducted your work on Planet Null.

Now for Bayes rule. Imagine you are on a space ship and for some reason you are interested in whether the person named Ella is healthy or sick. That is, you want to know whether Ella lives on Planet B_sick_ or Planet B_healthy_. You receive a radio message: Ella had a positive test result. Regretably, although you now know the test result for Ella, you're not sure whether the message came from Planet B_sick_ or Planet B_healthy_. Your radio detection finder points vaguely to Planet B_healthy_ but Planet B_sick_ is in the same general direction. So it might be either. You assess that the probability is twice as high that the origin is Planet B_sick_ than Planet B_healthy_.

To calculate the update the probabilities indicated by your radio direction finder with the received information that Ella's test result was positive, you do a specific calculation that involves two likelihoods: the likelihood of a + test result on Planet B_sick_ and the likelihood of a - test result on Planet B_healthy_. The higher the likelihood, the greater the probability that Ella lives on that planet. But you also have information from your radio direction finder. To make an overall judgement of whether Ella is more likely to be on Planet B_sick_ or Planet B_healthy_, you should combine the two sources of information. You can do by undertaking two different calculations of relative probability, the results of which can be compared to generate your conclusion.

i. the relative probability that Ella is sick. This is 
$$\underbrace{p(+\ \text{test result}\ given\ \text{Ella lives on Planet Sick})}_\text{A likelihood calculated on Planet Sick}\times \underbrace{p(\text{Message came from Planet Sick})}_\text{Based on the radio direction finder}$$
ii. the relative probability that Ella is healthy. This is very similar:
$$\underbrace{p(+\ \text{test result}\ given\ \text{Ella lives on Planet Healthy})}_\text{A likelihood calculated on Planet Healthy}\times \underbrace{p(\text{Message came from Planet Healthy})}_\text{Based on the radio direction finder}$$
Dividing (i) by (ii) gives the "odds" of Ella living on Planet B_sick_. Odds are easily converted into probabilities, if that's what you want. Actually, Bayes rule has a particularly nice form when there are only two hypotheses involved.

$$\underbrace{Odds(\text{Sick} | + )}_\text{posterior odds} = \underbrace{\frac{Likelihood(+ | \text{Sick})}{Likelihood(+ | \text{Healthy})}}_\text{Likelihood ratio} \times \underbrace{Odds(\text{Sick} | \text{radio direction finder})}_\text{prior odds}$$

A likelihood is merely the probability of a given observation *given* that you are on a particular hypothetical planet.

